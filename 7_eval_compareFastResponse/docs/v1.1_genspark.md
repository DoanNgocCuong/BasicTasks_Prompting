T√¥i s·∫Ω t·∫°o t·ª´ng file Python tr·ª±c ti·∫øp cho b·∫°n:

## 1. get_data_conversation.py

```python
import requests
import json
import os
from typing import Optional

class ConversationDataFetcher:
    def __init__(self, api_token: str):
        self.api_token = api_token
        self.base_url = "https://robot-api.hacknao.edu.vn/robot/api/v1/admin/conversations"
        self.headers = {
            'X-API-Key': api_token,
            'accept': 'application/json'
        }
        
        # T·∫°o folder input n·∫øu ch∆∞a c√≥
        if not os.path.exists('input'):
            os.makedirs('input')
    
    def fetch_conversation(self, conversation_id: str) -> Optional[dict]:
        """
        L·∫•y d·ªØ li·ªáu conversation t·ª´ API
        """
        url = f"{self.base_url}/{conversation_id}"
        
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            
            data = response.json()
            print(f"‚úÖ L·∫•y d·ªØ li·ªáu th√†nh c√¥ng cho conversation ID: {conversation_id}")
            return data
            
        except requests.exceptions.RequestException as e:
            print(f"‚ùå L·ªói khi l·∫•y d·ªØ li·ªáu cho conversation ID {conversation_id}: {e}")
            return None
    
    def save_to_file(self, conversation_id: str, data: dict) -> str:
        """
        L∆∞u d·ªØ li·ªáu v√†o file JSON
        """
        filename = f"input/conversation_{conversation_id}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ ƒê√£ l∆∞u d·ªØ li·ªáu v√†o: {filename}")
            return filename
            
        except Exception as e:
            print(f"‚ùå L·ªói khi l∆∞u file {filename}: {e}")
            return ""
    
    def fetch_and_save(self, conversation_id: str) -> str:
        """
        L·∫•y v√† l∆∞u d·ªØ li·ªáu conversation
        """
        data = self.fetch_conversation(conversation_id)
        if data:
            return self.save_to_file(conversation_id, data)
        return ""

if __name__ == "__main__":
    # Test v·ªõi token m·∫´u
    TOKEN = "{{token}}"  # Thay th·∫ø b·∫±ng token th·ª±c
    
    fetcher = ConversationDataFetcher(TOKEN)
    
    # Test v·ªõi ID m·∫´u
    test_ids = ["8532", "358", "359", "362"]
    
    for conv_id in test_ids:
        print(f"\nüîÑ ƒêang x·ª≠ l√Ω conversation ID: {conv_id}")
        fetcher.fetch_and_save(conv_id)
```

## 2. processed.py

```python
import json
import pandas as pd
import os
from typing import List, Dict, Any

class ConversationProcessor:
    def __init__(self):
        pass
    
    def load_json_data(self, filepath: str) -> Dict[Any, Any]:
        """
        Load d·ªØ li·ªáu t·ª´ file JSON
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return data
        except Exception as e:
            print(f"‚ùå L·ªói khi ƒë·ªçc file {filepath}: {e}")
            return {}
    
    def extract_conversations(self, data: Dict[Any, Any]) -> List[Dict[str, Any]]:
        """
        Tr√≠ch xu·∫•t v√† t·ªï ch·ª©c d·ªØ li·ªáu conversation
        """
        if 'data' not in data:
            print("‚ùå Kh√¥ng t√¨m th·∫•y key 'data' trong JSON")
            return []
        
        conversations = []
        current_conversation = []
        
        for item in data['data']:
            character = item.get('character', '')
            content = item.get('content', '')
            
            if character == 'BOT_RESPONSE_CONVERSATION':
                if current_conversation:
                    # K·∫øt th√∫c conversation hi·ªán t·∫°i
                    conversations.append({
                        'conversation': current_conversation.copy(),
                        'next_fast_response': '',
                        'next_bot_response': content
                    })
                
                # B·∫Øt ƒë·∫ßu conversation m·ªõi
                current_conversation = [{"role": "assistant", "content": content}]
                
            elif character == 'USER':
                if content != '-':  # B·ªè qua user input r·ªóng
                    current_conversation.append({"role": "user", "content": content})
                    
            elif character == 'FAST_RESPONSE':
                # C·∫≠p nh·∫≠t fast response cho conversation g·∫ßn nh·∫•t
                if conversations:
                    conversations[-1]['next_fast_response'] = content
        
        return conversations
    
    def format_conversation_column(self, conversation: List[Dict[str, str]]) -> str:
        """
        Format conversation th√†nh string JSON
        """
        return json.dumps(conversation, ensure_ascii=False)
    
    def process_to_dataframe(self, conversations: List[Dict[str, Any]]) -> pd.DataFrame:
        """
        Chuy·ªÉn ƒë·ªïi conversations th√†nh DataFrame
        """
        processed_data = []
        
        for conv in conversations:
            processed_data.append({
                'BOT_RESPONSE_CONVERSATION_with_USER': self.format_conversation_column(conv['conversation']),
                'FAST_RESPONSE_next': conv['next_fast_response'],
                'BOT_RESPONSE_CONVERSATION_next': conv['next_bot_response']
            })
        
        return pd.DataFrame(processed_data)
    
    def process_file(self, input_filepath: str, output_filepath: str) -> bool:
        """
        X·ª≠ l√Ω file JSON v√† xu·∫•t ra Excel
        """
        try:
            # Load d·ªØ li·ªáu
            data = self.load_json_data(input_filepath)
            if not data:
                return False
            
            # Tr√≠ch xu·∫•t conversations
            conversations = self.extract_conversations(data)
            if not conversations:
                print("‚ùå Kh√¥ng t√¨m th·∫•y conversation n√†o")
                return False
            
            # T·∫°o DataFrame
            df = self.process_to_dataframe(conversations)
            
            # Xu·∫•t ra Excel
            df.to_excel(output_filepath, index=False, engine='openpyxl')
            print(f"‚úÖ ƒê√£ xu·∫•t d·ªØ li·ªáu ra: {output_filepath}")
            print(f"üìä S·ªë l∆∞·ª£ng conversations: {len(conversations)}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω file: {e}")
            return False

def process_all_input_files():
    """
    X·ª≠ l√Ω t·∫•t c·∫£ file trong folder input
    """
    processor = ConversationProcessor()
    
    if not os.path.exists('input'):
        print("‚ùå Folder 'input' kh√¥ng t·ªìn t·∫°i")
        return
    
    # T·∫°o folder output n·∫øu ch∆∞a c√≥
    if not os.path.exists('output'):
        os.makedirs('output')
    
    # X·ª≠ l√Ω t·ª´ng file JSON trong folder input
    for filename in os.listdir('input'):
        if filename.endswith('.json'):
            input_path = os.path.join('input', filename)
            output_filename = filename.replace('.json', '_processed.xlsx')
            output_path = os.path.join('output', output_filename)
            
            print(f"\nüîÑ ƒêang x·ª≠ l√Ω: {filename}")
            processor.process_file(input_path, output_path)

if __name__ == "__main__":
    process_all_input_files()
```

## 3. run_eval_api_fast_response.py

```python
import pandas as pd
import requests
import json
import time
from typing import Dict, List, Any
import os

class FastResponseEvaluator:
    def __init__(self):
        self.api_url = "http://103.253.20.30:8990/fast_response/generate"
        self.headers = {
            'accept': 'application/json',
            'Content-Type': 'application/json'
        }
    
    def call_fast_response_api(self, conversations: List[Dict[str, str]]) -> str:
        """
        G·ªçi API fast response
        """
        payload = {
            "conversations": conversations,
            "system_prompt": "You are QuickReact: detect the emotion in the latest message and reply instantly in its same language (English or Vietnamese) using 1-8 words (‚â§60 chars), keep it short enough with a friendly informal tone that mirrors and empathizes with that feeling (sad ‚Üí soothe, happy ‚Üí cheer, worried ‚Üí reassure; emojis/!/? welcome); output only that text‚Äînever answer the question, just buy time until the main reply arrives.",
            "model_name": "Qwen/Qwen3-4B",
            "temperature": 0.8,
            "top_p": 1
        }
        
        try:
            response = requests.post(self.api_url, headers=self.headers, json=payload, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            # Gi·∫£ s·ª≠ API tr·∫£ v·ªÅ response trong field 'content' ho·∫∑c t∆∞∆°ng t·ª±
            if isinstance(result, dict):
                return result.get('response', result.get('content', str(result)))
            return str(result)
            
        except requests.exceptions.Timeout:
            print("‚è∞ API timeout")
            return "API_TIMEOUT"
        except requests.exceptions.RequestException as e:
            print(f"‚ùå API Error: {e}")
            return f"API_ERROR: {str(e)}"
        except Exception as e:
            print(f"‚ùå Unexpected error: {e}")
            return f"ERROR: {str(e)}"
    
    def parse_conversation_string(self, conv_str: str) -> List[Dict[str, str]]:
        """
        Parse conversation string th√†nh list
        """
        try:
            return json.loads(conv_str)
        except json.JSONDecodeError:
            print(f"‚ùå L·ªói parse conversation: {conv_str[:100]}...")
            return []
    
    def evaluate_excel_file(self, input_filepath: str, output_filepath: str) -> bool:
        """
        ƒê√°nh gi√° file Excel v√† t·∫°o file output
        """
        try:
            # ƒê·ªçc file Excel
            df = pd.read_excel(input_filepath)
            print(f"üìä ƒê√£ ƒë·ªçc {len(df)} rows t·ª´ {input_filepath}")
            
            # Th√™m c·ªôt generated_ai
            df['generated_ai'] = ''
            
            # X·ª≠ l√Ω t·ª´ng row
            for index, row in df.iterrows():
                print(f"üîÑ ƒêang x·ª≠ l√Ω row {index + 1}/{len(df)}")
                
                conv_str = row['BOT_RESPONSE_CONVERSATION_with_USER']
                conversations = self.parse_conversation_string(conv_str)
                
                if conversations:
                    # G·ªçi API
                    generated_response = self.call_fast_response_api(conversations)
                    df.at[index, 'generated_ai'] = generated_response
                    
                    # Delay ƒë·ªÉ tr√°nh spam API
                    time.sleep(0.5)
                else:
                    df.at[index, 'generated_ai'] = "PARSE_ERROR"
                
                # In progress m·ªói 10 rows
                if (index + 1) % 10 == 0:
                    print(f"‚úÖ ƒê√£ ho√†n th√†nh {index + 1}/{len(df)} rows")
            
            # L∆∞u file output
            df.to_excel(output_filepath, index=False, engine='openpyxl')
            print(f"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ ra: {output_filepath}")
            
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói khi ƒë√°nh gi√° file: {e}")
            return False
    
    def evaluate_all_processed_files(self):
        """
        ƒê√°nh gi√° t·∫•t c·∫£ file processed trong folder output
        """
        if not os.path.exists('output'):
            print("‚ùå Folder 'output' kh√¥ng t·ªìn t·∫°i")
            return
        
        # T·∫°o folder eval n·∫øu ch∆∞a c√≥
        if not os.path.exists('eval'):
            os.makedirs('eval')
        
        for filename in os.listdir('output'):
            if filename.endswith('_processed.xlsx'):
                input_path = os.path.join('output', filename)
                output_filename = filename.replace('_processed.xlsx', '_output_eval.xlsx')
                output_path = os.path.join('eval', output_filename)
                
                print(f"\nüîÑ ƒêang ƒë√°nh gi√°: {filename}")
                self.evaluate_excel_file(input_path, output_path)

if __name__ == "__main__":
    evaluator = FastResponseEvaluator()
    evaluator.evaluate_all_processed_files()
```

## 4. main.py

```python
import sys
import argparse
import os
import pandas as pd
from get_data_conversation import ConversationDataFetcher
from processed import ConversationProcessor
from run_eval_api_fast_response import FastResponseEvaluator

class FastResponsePipeline:
    def __init__(self, api_token: str):
        self.api_token = api_token
        self.fetcher = ConversationDataFetcher(api_token)
        self.processor = ConversationProcessor()
        self.evaluator = FastResponseEvaluator()
        
        # T·∫°o c√°c folder c·∫ßn thi·∫øt
        for folder in ['input', 'output', 'eval', 'final']:
            if not os.path.exists(folder):
                os.makedirs(folder)
    
    def process_single_id(self, conversation_id: str) -> dict:
        """
        X·ª≠ l√Ω m·ªôt conversation ID
        """
        print(f"\n{'='*50}")
        print(f"üîÑ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω conversation ID: {conversation_id}")
        print(f"{'='*50}")
        
        results = {
            'id': conversation_id,
            'fetch_status': 'FAILED',
            'process_status': 'FAILED',
            'eval_status': 'FAILED',
            'input_file': '',
            'processed_file': '',
            'eval_file': ''
        }
        
        # B∆∞·ªõc 1: L·∫•y d·ªØ li·ªáu
        print(f"üì• B∆∞·ªõc 1: L·∫•y d·ªØ li·ªáu t·ª´ API...")
        input_file = self.fetcher.fetch_and_save(conversation_id)
        if input_file:
            results['fetch_status'] = 'SUCCESS'
            results['input_file'] = input_file
        else:
            print(f"‚ùå Kh√¥ng th·ªÉ l·∫•y d·ªØ li·ªáu cho ID: {conversation_id}")
            return results
        
        # B∆∞·ªõc 2: X·ª≠ l√Ω d·ªØ li·ªáu
        print(f"‚öôÔ∏è B∆∞·ªõc 2: X·ª≠ l√Ω d·ªØ li·ªáu...")
        processed_file = f"output/conversation_{conversation_id}_processed.xlsx"
        if self.processor.process_file(input_file, processed_file):
            results['process_status'] = 'SUCCESS'
            results['processed_file'] = processed_file
        else:
            print(f"‚ùå Kh√¥ng th·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu cho ID: {conversation_id}")
            return results
        
        # B∆∞·ªõc 3: ƒê√°nh gi√° v·ªõi API
        print(f"ü§ñ B∆∞·ªõc 3: ƒê√°nh gi√° v·ªõi Fast Response API...")
        eval_file = f"eval/conversation_{conversation_id}_output_eval.xlsx"
        if self.evaluator.evaluate_excel_file(processed_file, eval_file):
            results['eval_status'] = 'SUCCESS'
            results['eval_file'] = eval_file
        else:
            print(f"‚ùå Kh√¥ng th·ªÉ ƒë√°nh gi√° cho ID: {conversation_id}")
            return results
        
        print(f"‚úÖ Ho√†n th√†nh x·ª≠ l√Ω ID: {conversation_id}")
        return results
    
    def create_final_excel(self, results: list, output_file: str):
        """
        T·∫°o file Excel cu·ªëi c√πng v·ªõi m·ªói ID l√† m·ªôt sheet
        """
        print(f"\nüìä T·∫°o file Excel t·ªïng h·ª£p: {output_file}")
        
        try:
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                # T·∫°o sheet t·ªïng quan
                summary_data = []
                for result in results:
                    summary_data.append({
                        'ID': result['id'],
                        'Fetch Status': result['fetch_status'],
                        'Process Status': result['process_status'],
                        'Eval Status': result['eval_status'],
                        'Input File': result['input_file'],
                        'Processed File': result['processed_file'],
                        'Eval File': result['eval_file']
                    })
                
                summary_df = pd.DataFrame(summary_data)
                summary_df.to_excel(writer, sheet_name='Summary', index=False)
                
                # T·∫°o sheet cho t·ª´ng ID
                for result in results:
                    if result['eval_status'] == 'SUCCESS' and os.path.exists(result['eval_file']):
                        try:
                            df = pd.read_excel(result['eval_file'])
                            sheet_name = f"ID_{result['id']}"
                            df.to_excel(writer, sheet_name=sheet_name, index=False)
                            print(f"‚úÖ ƒê√£ th√™m sheet: {sheet_name}")
                        except Exception as e:
                            print(f"‚ùå L·ªói khi th√™m sheet cho ID {result['id']}: {e}")
            
            print(f"‚úÖ ƒê√£ t·∫°o file t·ªïng h·ª£p: {output_file}")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫°o file Excel t·ªïng h·ª£p: {e}")
            # T·∫°o file backup ƒë∆°n gi·∫£n
            backup_file = output_file.replace('.xlsx', '_backup.csv')
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_csv(backup_file, index=False, encoding='utf-8')
            print(f"üìÑ ƒê√£ t·∫°o file backup CSV: {backup_file}")
    
    def run_pipeline(self, conversation_ids: list):
        """
        Ch·∫°y pipeline cho danh s√°ch conversation IDs
        """
        print(f"üöÄ B·∫Øt ƒë·∫ßu pipeline v·ªõi {len(conversation_ids)} conversation IDs")
        print(f"üìã Danh s√°ch IDs: {', '.join(conversation_ids)}")
        
        results = []
        
        for conv_id in conversation_ids:
            result = self.process_single_id(conv_id)
            results.append(result)
        
        # T·∫°o file Excel t·ªïng h·ª£p
        timestamp = pd.Timestamp.now().strftime("%Y%m%d_%H%M%S")
        final_file = f"final/fast_response_evaluation_{timestamp}.xlsx"
        self.create_final_excel(results, final_file)
        
        # In b√°o c√°o t√≥m t·∫Øt
        self.print_summary_report(results)
        
        return results
    
    def print_summary_report(self, results: list):
        """
        In b√°o c√°o t√≥m t·∫Øt
        """
        print(f"\n{'='*60}")
        print(f"üìä B√ÅO C√ÅO T√ìM T·∫ÆT")
        print(f"{'='*60}")
        
        total = len(results)
        success_fetch = sum(1 for r in results if r['fetch_status'] == 'SUCCESS')
        success_process = sum(1 for r in results if r['process_status'] == 'SUCCESS')
        success_eval = sum(1 for r in results if r['eval_status'] == 'SUCCESS')
        
        print(f"üìà T·ªïng s·ªë IDs x·ª≠ l√Ω: {total}")
        print(f"üì• Fetch th√†nh c√¥ng: {success_fetch}/{total} ({success_fetch/total*100:.1f}%)")
        print(f"‚öôÔ∏è Process th√†nh c√¥ng: {success_process}/{total} ({success_process/total*100:.1f}%)")
        print(f"ü§ñ Eval th√†nh c√¥ng: {success_eval}/{total} ({success_eval/total*100:.1f}%)")
        
        # Chi ti·∫øt t·ª´ng ID
        print(f"\nüìã Chi ti·∫øt t·ª´ng ID:")
        for result in results:
            status_icon = "‚úÖ" if result['eval_status'] == 'SUCCESS' else "‚ùå"
            print(f"{status_icon} ID {result['id']}: {result['eval_status']}")
        
        # Files ƒë∆∞·ª£c t·∫°o
        print(f"\nüìÅ Files ƒë∆∞·ª£c t·∫°o:")
        for result in results:
            if result['eval_status'] == 'SUCCESS':
                print(f"   üìÑ {result['eval_file']}")

def parse_arguments():
    """
    Parse command line arguments
    """
    parser = argparse.ArgumentParser(description='Fast Response Evaluation Pipeline')
    
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--ids', nargs='+', help='Conversation IDs (space separated)')
    group.add_argument('--id_file', type=str, help='File containing conversation IDs (one per line)')
    
    parser.add_argument('--token', type=str, default='{{token}}', 
                       help='API token (default: {{token}})')
    
    return parser.parse_args()

def read_ids_from_file(filepath: str) -> list:
    """
    ƒê·ªçc IDs t·ª´ file
    """
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            ids = [line.strip() for line in f if line.strip()]
        return ids
    except Exception as e:
        print(f"‚ùå L·ªói khi ƒë·ªçc file {filepath}: {e}")
        return []

def main():
    """
    H√†m main
    """
    args = parse_arguments()
    
    # L·∫•y danh s√°ch IDs
    if args.ids:
        conversation_ids = args.ids
    elif args.id_file:
        conversation_ids = read_ids_from_file(args.id_file)
        if not conversation_ids:
            print("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc IDs t·ª´ file")
            sys.exit(1)
    else:
        print("‚ùå C·∫ßn cung c·∫•p --ids ho·∫∑c --id_file")
        sys.exit(1)
    
    # Kh·ªüi t·∫°o v√† ch·∫°y pipeline
    pipeline = FastResponsePipeline(args.token)
    pipeline.run_pipeline(conversation_ids)

if __name__ == "__main__":
    # N·∫øu ch·∫°y tr·ª±c ti·∫øp m√† kh√¥ng c√≥ args, d√πng test IDs
    if len(sys.argv) == 1:
        print("üß™ Ch·∫ø ƒë·ªô test v·ªõi IDs m·∫∑c ƒë·ªãnh")
        test_ids = ["358", "359", "362"]
        pipeline = FastResponsePipeline("{{token}}")
        pipeline.run_pipeline(test_ids)
    else:
        main()

```

## 5. requirements.txt

```txt
requests>=2.31.0
pandas>=2.0.0
openpyxl>=3.1.0
```

## 6. H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng

T·∫°o file `README.md`:

```markdown
# Fast Response Evaluation System

## C√†i ƒë·∫∑t
```bash
pip install -r requirements.txt
```

## C√°ch s·ª≠ d·ª•ng

### 1. Ch·∫°y v·ªõi IDs tr·ª±c ti·∫øp
```bash
python main.py --ids 358 359 362 --token YOUR_API_TOKEN
```

### 2. Ch·∫°y v·ªõi file ch·ª©a IDs
T·∫°o file `ids.txt`:
```
358
359
362
8532
```

Ch·∫°y:
```bash
python main.py --id_file ids.txt --token YOUR_API_TOKEN
```

### 3. Ch·∫°y test mode
```bash
python main.py
```

## Output
- `final/fast_response_evaluation_YYYYMMDD_HHMMSS.xlsx`: File t·ªïng h·ª£p v·ªõi m·ªói ID l√† m·ªôt sheet
```

## Ti√™u ch√≠ ƒë√°nh gi√° Fast Response

T·∫°o file `evaluation_criteria.md`:

```markdown
# Ti√™u ch√≠ ƒë√°nh gi√° Fast Response

## 1. Ti√™u ch√≠ ch·∫•t l∆∞·ª£ng
- **ƒê·ªô ph√π h·ª£p c·∫£m x√∫c**: Response c√≥ ph·∫£n √°nh ƒë√∫ng c·∫£m x√∫c trong tin nh·∫Øn kh√¥ng?
- **ƒê·ªô d√†i ph√π h·ª£p**: 1-8 t·ª´, ‚â§60 k√Ω t·ª±
- **Ng√¥n ng·ªØ**: S·ª≠ d·ª•ng ƒë√∫ng ng√¥n ng·ªØ c·ªßa user (Vietnamese/English)
- **T√¥ng ƒëi·ªáu**: Th√¢n thi·ªán, kh√¥ng ch√≠nh th·ª©c, ƒë·ªìng c·∫£m

## 2. Ti√™u ch√≠ k·ªπ thu·∫≠t
- **Th·ªùi gian ph·∫£n h·ªìi**: < 2 gi√¢y
- **T·ª∑ l·ªá th√†nh c√¥ng**: > 95%
- **X·ª≠ l√Ω l·ªói**: Graceful degradation

## 3. Thang ƒëi·ªÉm (1-5)
- **5**: Xu·∫•t s·∫Øc - Ho√†n h·∫£o v·ªÅ m·ªçi m·∫∑t
- **4**: T·ªët - ƒê·∫°t y√™u c·∫ßu v·ªõi m·ªôt v√†i ƒëi·ªÉm nh·ªè
- **3**: Kh√° - ƒê·∫°t y√™u c·∫ßu c∆° b·∫£n
- **2**: Y·∫øu - C√≥ v·∫•n ƒë·ªÅ v·ªÅ ch·∫•t l∆∞·ª£ng
- **1**: K√©m - Kh√¥ng ƒë·∫°t y√™u c·∫ßu
```

T·∫•t c·∫£ c√°c file ƒë√£ s·∫µn s√†ng ƒë·ªÉ s·ª≠ d·ª•ng! B·∫°n c√≥ th·ªÉ ch·∫°y h·ªá th·ªëng b·∫±ng c√°ch:

1. Thay th·∫ø `{{token}}` b·∫±ng token th·ª±c c·ªßa b·∫°n
2. Ch·∫°y `python main.py --ids 358 359 362 --token YOUR_TOKEN`

H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω t·∫•t c·∫£ c√°c b∆∞·ªõc v√† t·∫°o file Excel t·ªïng h·ª£p cu·ªëi c√πng.




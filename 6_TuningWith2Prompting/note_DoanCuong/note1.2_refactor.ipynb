{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Tôi sẽ tách code thành các module riêng biệt:\n",
    "\n",
    "1. `utils_convert_roles_for_api.py`:\n",
    "```python:6_TuningWith2Prompting/utils_convert_roles_for_api.py\n",
    "def convert_roles_for_api(messages, is_roleA_turn=True):\n",
    "    \"\"\"\n",
    "    Chuyển đổi roleA/roleB thành user/assistant cho OpenAI API\n",
    "    is_roleA_turn: True nếu đang là lượt của roleA, False nếu là lượt của roleB\n",
    "    \"\"\"\n",
    "    converted_messages = []\n",
    "    for msg in messages:\n",
    "        if is_roleA_turn:\n",
    "            if msg[\"role\"] == \"roleA\":\n",
    "                role = \"assistant\"\n",
    "            else:\n",
    "                role = \"user\"\n",
    "        else:\n",
    "            if msg[\"role\"] == \"roleB\":\n",
    "                role = \"assistant\"\n",
    "            else:\n",
    "                role = \"user\"\n",
    "        \n",
    "        converted_messages.append({\n",
    "            \"role\": role,\n",
    "            \"content\": msg[\"content\"]\n",
    "        })\n",
    "    return converted_messages\n",
    "```\n",
    "\n",
    "2. `def_promptA.py`:\n",
    "```python:6_TuningWith2Prompting/def_promptA.py\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from utils_convert_roles_for_api import convert_roles_for_api\n",
    "\n",
    "def generate_roleA_response(client, roleA_prompt, message_history):\n",
    "    \"\"\"Generate response for roleA\"\"\"\n",
    "    print(\"\\n=== RoleA Turn ===\")\n",
    "    print(\"Original message history:\")\n",
    "    print(json.dumps(message_history, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    api_messages = [{\"role\": \"system\", \"content\": roleA_prompt}]\n",
    "    if message_history:\n",
    "        converted_history = convert_roles_for_api(message_history, is_roleA_turn=True)\n",
    "        api_messages.extend(converted_history)\n",
    "        print(\"\\nConverted history for RoleA:\")\n",
    "        print(json.dumps(api_messages, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=api_messages,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return response.choices[0].message.content, end_time - start_time\n",
    "```\n",
    "\n",
    "3. `def_promptB.py`:\n",
    "```python:6_TuningWith2Prompting/def_promptB.py\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from utils_convert_roles_for_api import convert_roles_for_api\n",
    "\n",
    "def generate_roleB_response(client, roleB_prompt, message_history):\n",
    "    \"\"\"Generate response for roleB\"\"\"\n",
    "    print(\"\\n=== RoleB Turn ===\")\n",
    "    print(\"Original message history:\")\n",
    "    print(json.dumps(message_history, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    api_messages = [{\"role\": \"system\", \"content\": roleB_prompt}]\n",
    "    if message_history:\n",
    "        converted_history = convert_roles_for_api(message_history, is_roleA_turn=False)\n",
    "        api_messages.extend(converted_history)\n",
    "        print(\"\\nConverted history for RoleB:\")\n",
    "        print(json.dumps(api_messages, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=api_messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    \n",
    "    return response.choices[0].message.content, end_time - start_time\n",
    "```\n",
    "\n",
    "4. `utils_export_conversations_to_excel.py`:\n",
    "```python:6_TuningWith2Prompting/utils_export_conversations_to_excel.py\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_export_data(all_messages):\n",
    "    \"\"\"Prepare data for export\"\"\"\n",
    "    print(\"\\n=== Preparing to Export Data ===\")\n",
    "    print(f\"Total messages to export: {len(all_messages)}\")\n",
    "    print(\"First few rows of data:\")\n",
    "    for i, msg in enumerate(all_messages[:3]):\n",
    "        print(f\"Row {i+1}: {msg}\")\n",
    "    return all_messages\n",
    "\n",
    "def validate_export_path(output_path):\n",
    "    \"\"\"Validate export path\"\"\"\n",
    "    if not output_path.endswith('.xlsx'):\n",
    "        output_path += '.xlsx'\n",
    "    return output_path\n",
    "```\n",
    "\n",
    "5. `export_conversations_to_excel.py`:\n",
    "```python:6_TuningWith2Prompting/export_conversations_to_excel.py\n",
    "import pandas as pd\n",
    "from utils_export_conversations_to_excel import prepare_export_data, validate_export_path\n",
    "\n",
    "def export_conversations_to_excel(all_messages, output_path):\n",
    "    \"\"\"Export all conversations and response times to an Excel file.\"\"\"\n",
    "    try:\n",
    "        # Prepare data\n",
    "        data = prepare_export_data(all_messages)\n",
    "        \n",
    "        # Validate output path\n",
    "        output_path = validate_export_path(output_path)\n",
    "        \n",
    "        # Create DataFrame and export\n",
    "        df_export = pd.DataFrame(data, \n",
    "                               columns=['Role', 'Content', 'Response_Time', \n",
    "                                      'RoleA_Prompt', 'RoleB_Prompt'])\n",
    "        df_export.to_excel(output_path, index=False)\n",
    "        print(f\"Conversations exported to {output_path}\")\n",
    "        \n",
    "    except PermissionError:\n",
    "        print(\"Error: Please close the Excel file before saving.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during export: {str(e)}\")\n",
    "```\n",
    "\n",
    "6. `main_v2.py`:\n",
    "```python:6_TuningWith2Prompting/main_v2.py\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import argparse\n",
    "from def_promptA import generate_roleA_response\n",
    "from def_promptB import generate_roleB_response\n",
    "from export_conversations_to_excel import export_conversations_to_excel\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def simulate_conversation(row):\n",
    "    \"\"\"Simulate a conversation based on the row of data.\"\"\"\n",
    "    message_history = []\n",
    "    response_times = []\n",
    "    conversationTurnCount = 0\n",
    "\n",
    "    # Extract and validate settings\n",
    "    roleA_prompt = str(row['roleA_prompt']) if not pd.isna(row['roleA_prompt']) else \"\"\n",
    "    roleB_prompt = str(row['roleB_prompt']) if not pd.isna(row['roleB_prompt']) else \"\"\n",
    "    initialConversationHistory = row['initialConversationHistory']\n",
    "    maxTurns = int(row['maxTurns']) if not pd.isna(row['maxTurns']) else 3\n",
    "\n",
    "    # Process conversation history\n",
    "    if not pd.isna(initialConversationHistory):\n",
    "        try:\n",
    "            history = json.loads(initialConversationHistory)\n",
    "            message_history.extend(history)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing conversation history: {e}\")\n",
    "\n",
    "    # Conversation loop\n",
    "    while conversationTurnCount < maxTurns:\n",
    "        try:\n",
    "            # RoleA's turn\n",
    "            roleA_message, roleA_time = generate_roleA_response(client, roleA_prompt, message_history)\n",
    "            message_history.append({\"role\": \"roleA\", \"content\": roleA_message})\n",
    "            response_times.append(roleA_time)\n",
    "\n",
    "            # RoleB's turn\n",
    "            roleB_message, roleB_time = generate_roleB_response(client, roleB_prompt, message_history)\n",
    "            message_history.append({\"role\": \"roleB\", \"content\": roleB_message})\n",
    "            response_times.append(roleB_time)\n",
    "\n",
    "            conversationTurnCount += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during conversation: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    return message_history, response_times\n",
    "\n",
    "def main(num_rows_to_process=None, input_file='2PromptingTuning.xlsx', output_file='result.xlsx'):\n",
    "    try:\n",
    "        # Load and process data\n",
    "        df = pd.read_excel(input_file)\n",
    "        num_rows = min(num_rows_to_process or len(df), len(df))\n",
    "        \n",
    "        all_messages = []\n",
    "        for index, row in df.head(num_rows).iterrows():\n",
    "            print(f\"\\n=== Processing Row {index + 1}/{num_rows} ===\")\n",
    "            \n",
    "            message_history, response_times = simulate_conversation(row)\n",
    "            \n",
    "            # Prepare export data\n",
    "            for i, msg in enumerate(message_history):\n",
    "                all_messages.append([\n",
    "                    msg['role'],\n",
    "                    msg['content'],\n",
    "                    response_times[i] if i < len(response_times) else 0,\n",
    "                    row['roleA_prompt'],\n",
    "                    row['roleB_prompt']\n",
    "                ])\n",
    "            all_messages.append(['Separator', '-------------------', 0, '', ''])\n",
    "        \n",
    "        # Export results\n",
    "        export_conversations_to_excel(all_messages, output_file)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Process conversations from Excel file')\n",
    "    parser.add_argument('--rows', type=int, help='Number of rows to process')\n",
    "    parser.add_argument('--input', type=str, default='2PromptingTuning.xlsx')\n",
    "    parser.add_argument('--output', type=str, default='result.xlsx')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    main(args.rows, args.input, args.output)\n",
    "```\n",
    "\n",
    "Cấu trúc thư mục sẽ là:\n",
    "```\n",
    "6_TuningWith2Prompting/\n",
    "├── utils_convert_roles_for_api.py\n",
    "├── def_promptA.py\n",
    "├── def_promptB.py\n",
    "├── utils_export_conversations_to_excel.py\n",
    "├── export_conversations_to_excel.py\n",
    "└── main_v2.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

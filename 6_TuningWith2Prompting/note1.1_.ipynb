{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, tôi hiểu vấn đề rồi. Khi gửi message history cho OpenAI API, chúng ta cần chuyển đổi roleA/roleB thành user/assistant tương ứng. Đây là cách sửa:\n",
    "\n",
    "```python:6_TuningWith2Prompting/main.py\n",
    "def convert_roles_for_api(messages, is_roleA_turn=True):\n",
    "    \"\"\"\n",
    "    Chuyển đổi roleA/roleB thành user/assistant cho OpenAI API\n",
    "    is_roleA_turn: True nếu đang là lượt của roleA, False nếu là lượt của roleB\n",
    "    \"\"\"\n",
    "    converted_messages = []\n",
    "    for msg in messages:\n",
    "        if is_roleA_turn:\n",
    "            # Khi là lượt của roleA\n",
    "            role = \"user\" if msg[\"role\"] == \"roleA\" else \"assistant\"\n",
    "        else:\n",
    "            # Khi là lượt của roleB\n",
    "            role = \"user\" if msg[\"role\"] == \"roleB\" else \"assistant\"\n",
    "        \n",
    "        converted_messages.append({\n",
    "            \"role\": role,\n",
    "            \"content\": msg[\"content\"]\n",
    "        })\n",
    "    return converted_messages\n",
    "\n",
    "def simulate_conversation(row):\n",
    "    \"\"\"Simulate a conversation based on the row of data.\"\"\"\n",
    "    message_history = []\n",
    "    response_times = []\n",
    "    conversationTurnCount = 0\n",
    "\n",
    "    # Extract settings from Excel row\n",
    "    roleA_prompt = row['roleA_prompt']\n",
    "    roleB_prompt = row['roleB_prompt']\n",
    "    initialConversationHistory = row['initialConversationHistory']\n",
    "    maxTurns = row['maxTurns']\n",
    "\n",
    "    # Parse and add conversation history if exists\n",
    "    history = parse_conversation_history(initialConversationHistory)\n",
    "    if history:\n",
    "        message_history.extend(history)\n",
    "        print(\"\\n=== Initial Conversation History ===\")\n",
    "        for msg in history:\n",
    "            print(f\"{msg['role']}: {msg['content']}\")\n",
    "    \n",
    "    # Start conversation loop\n",
    "    while conversationTurnCount < maxTurns:\n",
    "        try:\n",
    "            # Generate roleA message\n",
    "            start_time = time.time()\n",
    "            api_messages = [{\"role\": \"system\", \"content\": roleA_prompt}]\n",
    "            # Chuyển đổi history cho roleA\n",
    "            if message_history:\n",
    "                converted_history = convert_roles_for_api(message_history, is_roleA_turn=True)\n",
    "                api_messages.extend(converted_history)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=api_messages,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            roleA_message = response.choices[0].message.content\n",
    "            message_history.append({\"role\": \"roleA\", \"content\": roleA_message})\n",
    "            response_times.append(end_time - start_time)\n",
    "            print(f\"\\nRoleA: {roleA_message}\")\n",
    "            \n",
    "            # Generate roleB response\n",
    "            start_time = time.time()\n",
    "            api_messages = [{\"role\": \"system\", \"content\": roleB_prompt}]\n",
    "            # Chuyển đổi history cho roleB\n",
    "            if message_history:\n",
    "                converted_history = convert_roles_for_api(message_history, is_roleA_turn=False)\n",
    "                api_messages.extend(converted_history)\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=api_messages,\n",
    "                temperature=0\n",
    "            )\n",
    "            end_time = time.time()\n",
    "            roleB_message = response.choices[0].message.content\n",
    "            message_history.append({\"role\": \"roleB\", \"content\": roleB_message})\n",
    "            response_times.append(end_time - start_time)\n",
    "            print(f\"RoleB: {roleB_message}\")\n",
    "            \n",
    "            conversationTurnCount += 1\n",
    "            time.sleep(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during conversation: {str(e)}\")\n",
    "            break\n",
    "\n",
    "    return message_history, response_times\n",
    "```\n",
    "\n",
    "Những thay đổi chính:\n",
    "\n",
    "1. Thêm hàm `convert_roles_for_api` để chuyển đổi role:\n",
    "   - Khi là lượt của roleA:\n",
    "     - roleA -> user\n",
    "     - roleB -> assistant\n",
    "   - Khi là lượt của roleB:\n",
    "     - roleB -> user\n",
    "     - roleA -> assistant\n",
    "\n",
    "2. Áp dụng chuyển đổi role trước khi gọi API:\n",
    "   - Tạo api_messages riêng cho mỗi lượt\n",
    "   - Chuyển đổi history phù hợp với từng role\n",
    "\n",
    "3. Giữ nguyên format roleA/roleB trong message_history để lưu trữ\n",
    "\n",
    "Cách này sẽ giúp:\n",
    "- OpenAI API hiểu đúng context của cuộc hội thoại\n",
    "- Duy trì tính nhất quán của các role trong hội thoại\n",
    "- Tránh việc AI bị nhầm lẫn về vai trò của mình\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
